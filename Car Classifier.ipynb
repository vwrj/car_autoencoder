{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Why the fuck does it take 9500 examples for it to learn what a car is? That's actually idiotic. \n",
    "- What if you tell it: \"this is the car part of the image\". \n",
    "- I fucking liked the IG pictures after it's trained for 1 epoch. It gives back the windshield and the car and the wheels, sometimes. \n",
    "- How do I encourage that?\n",
    "- \n",
    "- What's the Vanilla CNN architecture for CIFAR-10?  \n",
    "- Would using a 'bad' autoencoder-classifier to do IG put a lot of salient pixels on the background, which we can then use to augment data with \"bad\" car examples?  \n",
    "- Wait. In my previous experiments, I only left the most salient pixels and said those were cars (label 1)??! No!! Those are \"not cars\" or 0 (np.zeros!!) so that it could learn to look at other stuff. \n",
    "- Take a rectangle of the most salient region. If car image, take truck image and stick salient image of car on truck image. Say this is still a truck. If you only take out 10% of salient pixels, they have neighbor regions around them. Model can learn from those pixels. Rectangle is fixed size. Find a way to put that rectangle such that you remove as much saliency as possible. Black out the rectangle. Do it for the other class too? Trucks? Find the most salient images. Start with cars and dogs.   \n",
    "- I noticed that after it's trained for 1 epoch, the ig gives you almost the entire car back. But it seems to focus on narrower and narrower parts of the image? Look at generalization error (on validation set) as you increase the number of epochs. It goes down as network learns and up after it overfits. Is IG focusing on narrower and narrower parts of the image but generalization error keeps going down?  \n",
    "  \n",
    "- Try classifier_one_epoch on different picture and see what the IG is: cars classified not as cars, animals classified as cars, etc. See exactly what it returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on here.   \n",
    "I wanted to train only on cars with salient pixels blacked out.   \n",
    "So I took those cars (~5000): images and labels (1). \n",
    "And I took the not_cars (~5000): images and labels (0). \n",
    "And I concatenated them. \n",
    "That should have been good. \n",
    "\n",
    "Do I actually have that?\n",
    "\n",
    "On the train set, is it picking up on the fact that images with black pixels randomly are cars? So then I have to fill them in with something else. Random noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1** \n",
    "- Train vanilla cnn for 2 epochs (so it's an \"okay\" model)\n",
    "- Find its most salient pixels (90%) and black them out (so a small black band within car or background)\n",
    "- Those images are still cars (label 1)\n",
    "- So add those to the training set and figure out if it can learn other car features. \n",
    "\n",
    "Result  \n",
    "- 824_100_epochs_fragmented_saliency_blots_very_good_separation  \n",
    "{'plane': 59, 'car': 824, 'bird': 16, 'cat': 13, 'deer': 4, 'dog': 8, 'frog': 18, 'horse': 10, 'ship': 95, 'truck': 264}  \n",
    "- IG's don't really look that much different. Mostly the same. Maybe the experimental one had a bit less with the background and features. Looked a ~ little bit less noisy. Not sure\n",
    "\n",
    "**Experiment 2**\n",
    "- Use trained model from Experiment 1. \n",
    "- Find its most salient pixels (80%) and black them out. \n",
    "- Those images are still cars (label 1). \n",
    "- So add those to the training set to figure out if it can learn other car features. \n",
    "- Basically you're fucking it and saying these are not salient pixels. Figure some other stuff out. \n",
    "\n",
    "Result  \n",
    "- Again, kind of whatever. \n",
    "- {'plane': 52, 'car': 868, 'bird': 29, 'cat': 39, 'deer': 17, 'dog': 26, 'frog': 32, 'horse': 26, 'ship': 106, 'truck': 306}\n",
    "- Maybe the experimental one had more background and features. Looked a ~ little bit less noisy. Not sure\n",
    "\n",
    "**Experiment 3**\n",
    "- Run Vanilla Car CNN. \n",
    "- Every epoch, check IG pictures. \n",
    "\n",
    "Result\n",
    "- Really interesting. After the 1st or 2nd epoch, the IG shows the entire car as being important. As number of epochs increases (3 and 5) it starts to focus on smaller and smaller parts of the image.  \n",
    "\n",
    "**Experiment 4**\n",
    "- Training only on pictures where all the cars have their salient pixels blotted out/static noise. \n",
    "- Dude idk. Neural network just predicts 0 and everything. Distribution of cars and not_cars is 50:50. \n",
    "- Eventually it just predicts 0 for everything. And it says the training loss is going down. \n",
    "- I honestly don't know. \n",
    "\n",
    "Results\n",
    "- When I change to top 1% salient random noise, it starts working again. But the results are like meh. \n",
    "\n",
    "**Experiment 5**\n",
    "- Plot validation loss per number of epochs of a vanilla car CNN. \n",
    "Results\n",
    "- Around 10-15 epochs is when test loss is at a minimum. After that it slowly increases. \n",
    "\n",
    "**Experiment 6**\n",
    "- For each increment of 5, generate ig examples (black and white) of the classifier on 5 different images. \n",
    "\n",
    "Results:\n",
    "- They look super cool. \n",
    "- By the first epoch, it gives you back the entire image of the car and the relevant background. \n",
    "- I still don't quite understand this. \n",
    "- When I plotted validation loss on test set, after 2-3 epochs, it reaches where its minimum is. \n",
    "- And then by later epochs, it gives you stripes of pixels inside the car (like a proto-car). \n",
    "- By epoch 56, it gets messier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each increment of 5, generate ig examples (black and white) of the classifier on 5 different images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Conv2D, Conv3D, MaxPooling2D, UpSampling2D, Flatten, Dropout, AveragePooling2D\n",
    "from keras.models import Model, load_model, model_from_json \n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.callbacks import EarlyStopping\n",
    "from utils.IntegratedGradients import * \n",
    "from utils.image_utils import get_images, save_image, plot_side_by_side, gray_scale\n",
    "from PIL import Image\n",
    "import random as random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# constants\n",
    "IMG_SIZE = 32\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cars from CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_CIFAR10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Pixel values go from 0 to 255. \n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "def select_car_images():\n",
    "    (x_train, y_train, x_test, y_test) = load_CIFAR10()\n",
    "\n",
    "    # we only want 'car' images (labeled 1): filter the rest out\n",
    "    not_cars = np.where(y_train!=1)[0]\n",
    "    x_train = np.delete(x_train, not_cars, axis=0)\n",
    "    y_train = np.delete(y_train, not_cars, axis=0)\n",
    "\n",
    "    not_cars = np.where(y_test!=1)[0]\n",
    "    x_test = np.delete(x_test, not_cars, axis=0)\n",
    "    y_test = np.delete(y_test, not_cars, axis=0)\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "# verify\n",
    "# (x_train, _, _, _) = select_car_images()\n",
    "# r = random.randint(0, x_train.shape[0]-1)\n",
    "# plt.imshow(x_train[r].reshape(IMG_SIZE, IMG_SIZE, 3))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Car Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train, x_test, y_test) = load_CIFAR10()\n",
    "\n",
    "\"\"\"\n",
    "We want a 50/50 split of cars and \"not_cars\" (birds, dogs, trucks, etc.)\n",
    "Currently training set has a 1:9 split of cars and not_cars (50,000 examples: 5,000 cars and 45,000 not-cars). \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# get indices of not_cars - should be 45,000 of them\n",
    "indices_not_cars = np.where(y_train!=1)[0] # cars labeled with '1'\n",
    "\n",
    "# delete 90% of the not_car rows so it's roughly equal: 5,000 cars and 4,500 not-cars. \n",
    "rows_to_delete = np.delete(indices_not_cars, np.s_[0:4500], axis=0)\n",
    "x_train = np.delete(x_train, rows_to_delete, axis=0)\n",
    "y_train = np.delete(y_train, rows_to_delete, axis=0)\n",
    "\n",
    "# save the actual labels (0-9 for each class, like 'airplane', 'car', 'bird', etc.)\n",
    "actual_labels = np.copy(y_train)\n",
    "# set the labels of not_cars to 0\n",
    "indices_not_cars = np.where(y_train!=1)[0] \n",
    "y_train[indices_not_cars] = 0\n",
    "print(x_train.shape[0])\n",
    "print(np.sum(y_train))\n",
    "\n",
    "# np.testing.assert_equal(x_train.shape[0], 9500)\n",
    "# np.testing.assert_equal(np.sum(y_train), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing images from directory:  /Users/vwr/fragmented_saliency_cars_top_5%/\n",
      "Saved training data into:  fragmented_saliency.npy\n",
      "Shape of training data: (4112, 32, 32, 3)\n",
      "(4112, 32, 32, 3)\n",
      "(4500, 32, 32, 3)\n",
      "(4500, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "fragmented_saliency = get_images('fragmented_saliency.npy', img_dir = '/Users/vwr/fragmented_saliency_cars_top_5%/',\n",
    "                                           refresh=True)\n",
    "\n",
    "### Combine fragmented saliency car images with non-car images for the train. \n",
    "(x_train, y_train, x_test, y_test) = load_CIFAR10()\n",
    "# get indices of not_cars - should be 45,000 of them\n",
    "indices_cars = np.where(y_train==1)[0] # cars labeled with '1'\n",
    "not_cars_x_train = np.delete(x_train, indices_cars, axis=0)\n",
    "not_cars_x_train = not_cars_x_train[0:4500, :, :, :]\n",
    "not_cars_y_train = np.delete(y_train, indices_cars, axis=0)\n",
    "not_cars_y_train = not_cars_y_train[0:4500, :]\n",
    "print(fragmented_saliency.shape)\n",
    "print(not_cars_x_train.shape)\n",
    "print(not_cars_y_train.shape)\n",
    "not_cars_y_train[:,:] = 0\n",
    "print(np.sum(not_cars_y_train))\n",
    "\n",
    "# def add_random_noise_to_images(imgs, num_pixels, black_out = False):\n",
    "#     for row in range(imgs.shape[0]):\n",
    "#         img = imgs[row]\n",
    "#         # find 10 random pixel locations (random locations from 0 to 32x32-1=1023)\n",
    "#         rand_idx = np.random.randint((IMG_SIZE * IMG_SIZE) - 1, size=num_pixels)\n",
    "#         for rand_i in rand_idx:\n",
    "#             rr = int(rand_i / IMG_SIZE)\n",
    "#             cc = rand_i % IMG_SIZE\n",
    "#             if black_out:\n",
    "#                 img[rr][cc] = 0\n",
    "#             else:\n",
    "#                 img[rr][cc][0] = np.random.random()\n",
    "#                 img[rr][cc][1] = np.random.random()\n",
    "#                 img[rr][cc][2] = np.random.random()\n",
    "            \n",
    "# add_random_noise_to_images(not_cars_x_train, 50, black_out = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and processing images from directory:  /Users/vwr/fragmented_saliency_non_cars_top_5%/\n",
      "Saved training data into:  fragmented_saliency_not_cars.npy\n",
      "Shape of training data: (4500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "fragmented_saliency_not_cars_x_train = get_images('fragmented_saliency_not_cars.npy', \n",
    "                                                  img_dir = '/Users/vwr/fragmented_saliency_non_cars_top_5%/',\n",
    "                                                  refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18112, 32, 32, 3)\n",
      "(18112, 1)\n",
      "9112.0\n",
      "9112\n"
     ]
    }
   ],
   "source": [
    "fragmented_saliency_y_train = np.ones((fragmented_saliency.shape[0], 1))\n",
    "salient_not_cars_train_x = np.concatenate((x_train, fragmented_saliency, fragmented_saliency_not_cars_x_train), axis=0)\n",
    "salient_not_cars_train_y = np.concatenate((y_train, fragmented_saliency_y_train, not_cars_y_train), axis=0)\n",
    "print(salient_not_cars_train_x.shape)\n",
    "print(salient_not_cars_train_y.shape)\n",
    "print(np.sum(salient_not_cars_train_y))\n",
    "print(len(np.where(salient_not_cars_train_y == 1)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225000\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.arange(salient_not_cars_train_x.shape[0])\n",
    "salient_not_cars_train_x = salient_not_cars_train_x[s]\n",
    "salient_not_cars_train_y = salient_not_cars_train_y[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(np.sum(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_train = np.concatenate((x_train, fragmented_saliency), axis = 0)\n",
    "print(car_train.shape)\n",
    "combined_y_train = np.concatenate((y_train, fragmented_saliency_y_train), axis = 0)\n",
    "print(combined_y_train.shape)\n",
    "print(np.sum(combined_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define architecture + fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 150)               614550    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                3020      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 767,095\n",
      "Trainable params: 767,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "from keras import losses\n",
    "\n",
    "input_img = Input(shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS))\n",
    "\n",
    "# build the network\n",
    "x = Dropout(0.15)(input_img)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2')(x)\n",
    "x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv3')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv4')(x)\n",
    "x = MaxPooling2D((2, 2,), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv5')(x)\n",
    "# encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(150, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "classifier = Model(input_img, x)\n",
    "classifier.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on augmented training set\n",
    "classifier.fit(car_train, combined_y_train, epochs=50, batch_size=256, shuffle=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n",
      "18112/18112 [==============================] - 125s - loss: 0.0541   \n",
      "Epoch 2/26\n",
      "17920/18112 [============================>.] - ETA: 1s - loss: 0.0372"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-b058b5c7c903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# y_test[indices_not_cars] = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# classifier.fit(x_train, y_train, epochs=26, batch_size=256, shuffle=True,) # validation_data=(x_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalient_not_cars_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalient_not_cars_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# validation_data=(x_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train on original training set\n",
    "# indices_not_cars = np.where(y_test!=1)[0] # cars labeled with '1'\n",
    "# y_test[indices_not_cars] = 0\n",
    "# classifier.fit(x_train, y_train, epochs=26, batch_size=256, shuffle=True,) # validation_data=(x_test, y_test)\n",
    "classifier.fit(salient_not_cars_train_x, salient_not_cars_train_y, epochs=26, batch_size=256, shuffle=True,) # validation_data=(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "(10000, 1)\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.5794    \n",
      " 9984/10000 [============================>.] - ETA: 0s0.408715263653\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.4386    \n",
      "10000/10000 [==============================] - 10s    \n",
      "0.382160759497\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.3477    \n",
      " 9952/10000 [============================>.] - ETA: 0s0.348455681157\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 28s - loss: 0.3412    \n",
      " 9952/10000 [============================>.] - ETA: 0s0.276396588087\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.3203    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.2907    \n",
      "10000/10000 [==============================] - 9s     \n",
      "0.263752645302\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.3001    \n",
      "10000/10000 [==============================] - 10s    \n",
      "0.17814319815\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.2586    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.2423    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.2252    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.2213    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.2103    \n",
      "10000/10000 [==============================] - 9s     \n",
      "0.170575515768\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1983    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1848    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.1602    \n",
      "10000/10000 [==============================] - 9s     \n",
      "0.155242917357\n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1780    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1533    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1282    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1181    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.1255    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.1032    \n",
      " 9984/10000 [============================>.] - ETA: 0sEpoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.0867    \n",
      "10000/10000 [==============================] - 10s    \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.0788    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.0764    \n",
      "10000/10000 [==============================] - 10s    \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 27s - loss: 0.0580    \n",
      "10000/10000 [==============================] - 10s    \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.0558    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0538    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0440    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0422    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0449    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0387    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0350    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0576    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 26s - loss: 0.0549    \n",
      "10000/10000 [==============================] - 9s     \n",
      "Epoch 1/1\n",
      "9500/9500 [==============================] - 25s - loss: 0.0299    \n",
      "10000/10000 [==============================] - 9s     \n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Generate Best Conv Classifier on original x_train and y_train\n",
    "###\n",
    "\n",
    "indices_not_cars = np.where(y_test!=1)[0] # cars labeled with '1'\n",
    "y_test[indices_not_cars] = 0\n",
    "print(np.sum(y_test))\n",
    "print(y_test.shape)\n",
    "\n",
    "nb_epochs = 35\n",
    "best_loss = 100\n",
    "for i in range(nb_epochs):\n",
    "    classifier.fit(x_train, y_train, batch_size=256, shuffle=True)\n",
    "    val_loss = classifier.evaluate(x_test, y_test)\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        print(best_loss)\n",
    "        classifier.save('best_vanilla_conv_model_val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32151479103565217"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUGSNLAoSJIGFgVJ0uA3ynltslZM3ZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x333efe9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.history.history.keys()\n",
    "plt.plot(classifier.history.history['loss'])\n",
    "plt.plot(classifier.history.history['val_loss'])\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.savefig('/Users/vwr/car autoencoder/car_autoencoder/Vanilla CNN Loss Learning Curve.jpeg')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_igs_at_epochs(data,\n",
    "                          model, \n",
    "                          experiment_no,\n",
    "                          experiment_dir='/Users/vwr/car autoencoder/car_autoencoder/Experiments/',\n",
    "                          test_idx=[82, 104, 105, 193, 204], \n",
    "                          ig_epochs=[1, 2, 5, 10, 15, 25]):\n",
    "    x_train, y_train, x_test, y_test = data\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    for ep in range(1, 30):\n",
    "        model.fit(x_train, y_train, epochs=1, batch_size=256, shuffle=True, validation_data=(x_test, y_test))\n",
    "        loss.append(model.history.history['loss'][0])\n",
    "        loss.append(model.history.history['val_loss'][0])\n",
    "        if ep in ig_epochs:\n",
    "            ig = integrated_gradients(classifier)\n",
    "            for idx in test_idx:\n",
    "                img = x_test[idx]\n",
    "                exp = process_exp(ig.explain(img))\n",
    "                exp_white = process_exp(ig.explain(img, reference=ref[0]))\n",
    "                vis = img*exp\n",
    "                vis_white = img*exp_white\n",
    "                vis_combined = vis + vis_white\n",
    "                \n",
    "                img_folder = experiment_dir + str(experiment_no) + '/' + str(idx)\n",
    "                save_image(img = vis,\n",
    "                           img_name = 'ig_' + str(idx) + 'epoch_' + str(ep) + '_black_baseline.jpeg',\n",
    "                           img_dir = img_folder)\n",
    "                save_image(img = vis_white,\n",
    "                           img_name = 'ig_' + str(idx) + 'epoch_' + str(ep) + '_white_baseline.jpeg',\n",
    "                           img_dir = img_folder)\n",
    "                save_image(img = vis_combined,\n",
    "                           img_name = 'ig_' + str(idx) + 'epoch_' + str(ep) + '_combined_baseline.jpeg',\n",
    "                           img_dir = img_folder + '/combined')\n",
    "\n",
    "\n",
    "            \n",
    "indices_not_cars = np.where(y_test!=1)[0] # cars labeled with '1'\n",
    "y_test[indices_not_cars] = 0\n",
    "\n",
    "# compute_igs_at_epochs(data = (x_train, y_train, x_test, y_test),\n",
    "#                       classifier, \n",
    "#                       experiment_no = 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(loss)\n",
    "# plt.plot(val_loss)\n",
    "# # plt.title('model accuracy')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.savefig('/Users/vwr/car autoencoder/car_autoencoder/Experiments/7/Vanilla CNN Loss Learning Curve.jpeg')\n",
    "# # plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on salient-blacked-out images only\n",
    "classifier.fit(salient_not_cars_train_x, salient_not_cars_train_y, \n",
    "               epochs=50, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "predictions[predictions < 0.5] = 0\n",
    "predictions[predictions >= 0.5] = 1\n",
    "print(predictions.shape)\n",
    "print(np.sum(predictions))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"./saved_models/824_100_epochs_fragmented_saliency_blots_very_good_separation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifier = load_model(\"./best_vanilla_conv_model_val_accuracy\")\n",
    "# Vanilla CNN\n",
    "classifier1 = load_model(\"./saved_models/852_100_epochs_car_classifier_from_scratch\")\n",
    "# classifier2 = load_model(\"./saved_models/761_car_classifier_first_2_frozen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "[[ 0.99867493]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAEfCAYAAABCncKKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRI1hCAAARO3/AUlEJJK5OXHgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3386fa978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQpH4hSgUiV+IQpH4hSgUiV+IQvk/plW3y4wRALEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x335276ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6, 37, 1020, 109, 123, 66, 81, 82, 104, 105, 114, 122, 134, 161, 193, 204, 231\n",
    "# wheels!\n",
    "# 6, 1020, 66, 81, 82, 105, 114, 122, 134, 161, 193, 204\n",
    "# misclassified: 57, 162, 339\n",
    "ig = integrated_gradients(classifier)\n",
    "ig2 = integrated_gradients(classifier1)\n",
    "ref = np.ones((32, 32, 3))\n",
    "ref = np.expand_dims(ref, axis=0)\n",
    "car_idx = 231\n",
    "img = x_test[car_idx]\n",
    "exp = ig.explain(img) # reference=ref[0]'\n",
    "exp_white = ig.explain(img, reference=ref[0])\n",
    "exp2 = ig2.explain(img, reference=ref[0])\n",
    "\n",
    "def process_exp(exp):\n",
    "    exp = gray_scale(exp)\n",
    "    exp = abs(exp)\n",
    "    exp = np.clip(exp/np.percentile(exp, 99.5), 0,1)  \n",
    "    return exp\n",
    "\n",
    "\n",
    "exp = process_exp(exp)\n",
    "exp_white = process_exp(exp_white)\n",
    "exp2 = process_exp(exp2)\n",
    "vis = img*exp_white + img*exp\n",
    "vis2 = img*exp2\n",
    "\n",
    "print(classifier.predict(img.reshape(1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "save_image(img = img*exp, img_name = str(car_idx) + '_black_baseline.jpeg',\n",
    "                           img_dir = '/Users/vwr/car autoencoder/car_autoencoder/Experiments/8 - Saliency works (IG pics)')\n",
    "\n",
    "save_image(img = img*exp_white, img_name = str(car_idx) + '_white_baseline.jpeg',\n",
    "                           img_dir = '/Users/vwr/car autoencoder/car_autoencoder/Experiments/8 - Saliency works (IG pics)')\n",
    "\n",
    "plot_side_by_side(img, vis, titles=[\"Original\", \"Explanation\"])\n",
    "plt.imshow(vis2)\n",
    "plt.show()\n",
    "### BLACK PIXEL experiment for IG with standard black image baseline\n",
    "### USE WHITE AND BLACK BASELINES to get pixels with higher attribution (lighter and darker)\n",
    "\n",
    "# rescaled1 = (255.0 / vis.max() * (vis - vis.min())).astype(np.uint8)\n",
    "# rescaled2 = (255.0 / vis2.max() * (vis2 - vis2.min())).astype(np.uint8)\n",
    "# im1 = Image.fromarray(rescaled1)\n",
    "# im2 = Image.fromarray(rescaled2)\n",
    "# img_name1 = 'ig_193_vanilla_cnn_8_epoch' + '.jpeg'  \n",
    "# img_name2 = 'ig_193_vanilla_cnn_trained' + '.jpeg' \n",
    "# im1.save(os.path.join('/Users/vwr/car autoencoder/car_autoencoder/Experiments/3/', img_name1))\n",
    "# im2.save(os.path.join('/Users/vwr/car autoencoder/car_autoencoder/Experiments/3/', img_name2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fragmented images from most salient pixels and add to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4112\n",
      "4177.0\n"
     ]
    }
   ],
   "source": [
    "# Vanilla CNN\n",
    "# classifier = load_model(\"./saved_models/852_100_epochs_car_classifier_from_scratch\")\n",
    "cars_train_i = []\n",
    "train_predictions = classifier.predict(x_train)\n",
    "train_predictions[train_predictions < 0.5] = 0\n",
    "train_predictions[train_predictions >= 0.5] = 1\n",
    "for i in range(train_predictions.shape[0]):\n",
    "    if train_predictions[i] == 1 and y_train[i] == 1:\n",
    "        cars_train_i.append(i)\n",
    "        \n",
    "print(len(cars_train_i))\n",
    "print(np.sum(train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.predict(x_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = load_model(\"./best_vanilla_conv_model_val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[486])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "[[ 0.81409878]]\n",
      "[[ 0.998348]]\n",
      "[[ 0.87944037]]\n",
      "[[ 0.30361179]]\n",
      "[[ 0.17026654]]\n",
      "[[ 0.52807105]]\n",
      "[[ 0.93443668]]\n",
      "[[ 0.94398379]]\n",
      "[[ 0.93946564]]\n",
      "[[ 0.38493705]]\n",
      "[[ 0.6189447]]\n",
      "[[ 0.12010291]]\n",
      "[[ 0.01472156]]\n",
      "[[ 0.94990963]]\n",
      "[[ 0.91966152]]\n",
      "[[ 0.40232089]]\n",
      "[[ 0.54619741]]\n",
      "[[ 0.83693767]]\n",
      "[[ 0.59885454]]\n",
      "[[ 0.90462381]]\n",
      "[[ 0.53885204]]\n",
      "[[ 0.99581003]]\n",
      "[[ 0.96460861]]\n",
      "[[ 0.84946924]]\n",
      "[[ 0.67156917]]\n",
      "[[ 0.25603712]]\n",
      "[[ 0.59073085]]\n",
      "[[ 0.87106198]]\n",
      "[[ 0.76662874]]\n",
      "[[ 0.98785955]]\n",
      "[[ 0.15778022]]\n",
      "[[ 0.99576795]]\n",
      "[[ 0.94079286]]\n",
      "[[ 0.97931665]]\n",
      "[[ 0.08495232]]\n",
      "[[ 0.76071411]]\n",
      "[[ 0.83614868]]\n",
      "[[ 0.73034739]]\n",
      "[[ 0.93673879]]\n",
      "[[ 0.82386094]]\n",
      "[[ 0.90989965]]\n",
      "[[ 0.14372933]]\n",
      "[[ 0.69726449]]\n",
      "[[ 0.58630961]]\n",
      "[[ 0.7055096]]\n",
      "[[ 0.55913883]]\n",
      "[[ 0.96922529]]\n",
      "[[ 0.09651811]]\n",
      "[[ 0.97973835]]\n",
      "[[ 0.82923651]]\n",
      "[[ 0.97407621]]\n",
      "[[ 0.58139968]]\n",
      "[[ 0.39909199]]\n",
      "[[ 0.52199709]]\n",
      "[[ 0.38676703]]\n",
      "[[ 0.95027786]]\n",
      "[[ 0.50402468]]\n",
      "[[ 0.00764482]]\n",
      "[[ 0.99578202]]\n",
      "[[ 0.76039773]]\n",
      "[[ 0.18265069]]\n",
      "[[ 0.84125829]]\n",
      "[[ 0.98677075]]\n",
      "[[ 0.9756276]]\n",
      "[[ 0.26454729]]\n",
      "[[ 0.00864985]]\n",
      "[[ 0.65249854]]\n",
      "[[ 0.85242236]]\n",
      "[[ 0.13791533]]\n",
      "[[ 0.92659169]]\n",
      "[[ 0.91639757]]\n",
      "[[ 0.60257775]]\n",
      "[[ 0.68332827]]\n",
      "[[ 0.51881635]]\n",
      "[[ 0.77604264]]\n",
      "[[ 0.14713413]]\n",
      "[[ 0.85934043]]\n",
      "[[ 0.95339108]]\n",
      "[[ 0.74583805]]\n",
      "[[ 0.46597683]]\n",
      "[[ 0.90382248]]\n",
      "[[ 0.9906742]]\n",
      "[[ 0.7936008]]\n"
     ]
    }
   ],
   "source": [
    "ig = integrated_gradients(classifier) # using vanilla CNN trained for 200 epochs\n",
    "k = 0\n",
    "for ind in cars_train_i:\n",
    "    img = np.copy(x_train[ind])\n",
    "    exp = ig.explain(img)\n",
    "    exp = gray_scale(exp)\n",
    "    exp = abs(exp)  \n",
    "    exp = np.clip(exp/np.percentile(exp, 99.99), 0,1)\n",
    "    \n",
    "    threshold = np.percentile(exp, 95)\n",
    "    count = 0\n",
    "    for i in range(exp.shape[0]):\n",
    "        for j in range(exp.shape[1]):\n",
    "            if np.any(exp[i][j] > threshold, axis=0):\n",
    "                count += 1\n",
    "                img[i][j][0] = 0\n",
    "                img[i][j][1] = 0\n",
    "                img[i][j][2] = 0\n",
    "    \n",
    "    rescaled = (255.0 / img.max() * (img - img.min())).astype(np.uint8)\n",
    "    if k % 50 == 0:\n",
    "        print(classifier.predict(img.reshape(1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    im = Image.fromarray(rescaled)\n",
    "    img_name = str(ind) + '_car.jpeg'  \n",
    "    im.save(os.path.join('/Users/vwr/fragmented_saliency_cars_top_5%/', img_name))\n",
    "    k += 1\n",
    "#     print(classifier.predict(img.reshape(1, IMG_SIZE, IMG_SIZE, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate fragmented saliency for non-cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated output channel (0-based index): All\n",
      "Building gradient functions\n",
      "Progress: 100.0%\n",
      "Done.\n",
      "[[ 0.68145275]]\n",
      "[[ 0.73879391]]\n",
      "[[ 0.00146403]]\n",
      "[[ 0.38373333]]\n",
      "[[ 0.99034685]]\n",
      "[[ 0.49132076]]\n",
      "[[ 0.01553091]]\n",
      "[[ 0.97045362]]\n",
      "[[ 0.91572422]]\n",
      "[[ 0.85539645]]\n",
      "[[ 0.17884463]]\n",
      "[[ 0.94366604]]\n",
      "[[ 0.75715172]]\n",
      "[[ 0.84017628]]\n",
      "[[ 0.56193942]]\n",
      "[[ 0.23408557]]\n",
      "[[ 0.90728486]]\n",
      "[[ 0.20637766]]\n",
      "[[ 0.24835031]]\n",
      "[[ 0.80201548]]\n",
      "[[ 0.01659775]]\n",
      "[[ 0.98315698]]\n",
      "[[ 0.23622471]]\n",
      "[[ 0.06677269]]\n",
      "[[ 0.24084057]]\n",
      "[[ 0.90947378]]\n",
      "[[ 0.77435207]]\n",
      "[[ 0.90130287]]\n",
      "[[ 0.25446165]]\n",
      "[[ 0.21045643]]\n",
      "[[ 0.68271679]]\n",
      "[[ 0.21215783]]\n",
      "[[ 0.79594058]]\n",
      "[[ 0.94575238]]\n",
      "[[ 0.02614246]]\n",
      "[[ 0.99496633]]\n",
      "[[ 0.11482271]]\n",
      "[[ 0.08944497]]\n",
      "[[ 0.4258]]\n",
      "[[ 0.6975345]]\n",
      "[[ 0.99130803]]\n",
      "[[ 0.15815166]]\n",
      "[[ 0.87683523]]\n",
      "[[ 0.03965757]]\n",
      "[[ 0.13686436]]\n",
      "[[ 0.27353522]]\n",
      "[[ 0.48967108]]\n",
      "[[ 0.4350138]]\n",
      "[[ 0.65586066]]\n",
      "[[ 0.94461155]]\n",
      "[[ 0.53883547]]\n",
      "[[ 0.95872587]]\n",
      "[[ 0.72292757]]\n",
      "[[ 0.5751223]]\n",
      "[[ 0.9077574]]\n",
      "[[ 0.4829964]]\n",
      "[[ 0.88916808]]\n",
      "[[ 0.03672297]]\n",
      "[[ 0.36527833]]\n",
      "[[ 0.00471018]]\n",
      "[[ 0.01422876]]\n",
      "[[ 0.73266494]]\n",
      "[[ 0.85603529]]\n",
      "[[ 0.02016716]]\n",
      "[[ 0.10286249]]\n",
      "[[ 0.179648]]\n",
      "[[ 0.1334963]]\n",
      "[[ 0.39737946]]\n",
      "[[ 0.99256778]]\n",
      "[[ 0.92695856]]\n",
      "[[ 0.08466561]]\n",
      "[[ 0.77008736]]\n",
      "[[ 0.89907897]]\n",
      "[[ 0.38612074]]\n",
      "[[ 0.73450702]]\n",
      "[[ 0.00862935]]\n",
      "[[ 0.14994423]]\n",
      "[[ 0.17255473]]\n",
      "[[ 0.08873209]]\n",
      "[[ 0.79686213]]\n",
      "[[ 0.11535109]]\n",
      "[[ 0.77844095]]\n",
      "[[ 0.1519382]]\n",
      "[[ 0.05613361]]\n",
      "[[ 0.26677692]]\n",
      "[[ 0.65847963]]\n",
      "[[ 0.02508774]]\n",
      "[[ 0.99282962]]\n",
      "[[ 0.3517541]]\n",
      "[[ 0.39727879]]\n"
     ]
    }
   ],
   "source": [
    "ig = integrated_gradients(classifier) # using vanilla CNN trained for 200 epochs\n",
    "k = 0\n",
    "for ind in range(not_cars_x_train.shape[0]):\n",
    "    img = np.copy(not_cars_x_train[ind])\n",
    "    exp = ig.explain(img)\n",
    "    exp = gray_scale(exp)\n",
    "    exp = abs(exp)  \n",
    "    exp = np.clip(exp/np.percentile(exp, 99.99), 0,1)\n",
    "    \n",
    "    threshold = np.percentile(exp, 95)\n",
    "    count = 0\n",
    "    for i in range(exp.shape[0]):\n",
    "        for j in range(exp.shape[1]):\n",
    "            if np.any(exp[i][j] > threshold, axis=0):\n",
    "                count += 1\n",
    "                img[i][j][0] = 0\n",
    "                img[i][j][1] = 0\n",
    "                img[i][j][2] = 0\n",
    "    \n",
    "    rescaled = (255.0 / img.max() * (img - img.min())).astype(np.uint8)\n",
    "    if k % 50 == 0:\n",
    "        print(classifier.predict(img.reshape(1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    im = Image.fromarray(rescaled)\n",
    "    img_name = str(ind) + '_car.jpeg'  \n",
    "    im.save(os.path.join('/Users/vwr/fragmented_saliency_non_cars_top_5%/', img_name))\n",
    "    k += 1\n",
    "#     print(classifier.predict(img.reshape(1, IMG_SIZE, IMG_SIZE, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier2.predict(x_test)\n",
    "predictions[predictions < 0.5] = 0\n",
    "predictions[predictions >= 0.5] = 1\n",
    "print(np.sum(predictions))\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Conv Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2 = classifier.layers[2]\n",
    "l3 = classifier.layers[3]\n",
    "l4 = classifier.layers[4]\n",
    "l5 = classifier.layers[5]\n",
    "l6 = classifier.layers[6]\n",
    "l7 = classifier.layers[7]\n",
    "l8 = classifier.layers[8]\n",
    "l9 = classifier.layers[9]\n",
    "l10 = classifier.layers[10]\n",
    "l12 = classifier.layers[12]\n",
    "l14 = classifier.layers[14]\n",
    "\n",
    "x = l2(classifier.input)\n",
    "x = l3(x)\n",
    "x = l4(x)\n",
    "x = l5(x)\n",
    "x = l6(x)\n",
    "x = l7(x)\n",
    "x = l8(x)\n",
    "x = l9(x)\n",
    "x = l10(x)\n",
    "x = l12(x)\n",
    "output = l14(x)\n",
    "\n",
    "classifier = Model(classifier.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Conv Filters\n",
    "from keras import backend as K\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "#     x = x.transpose((0, 1, 2))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in classifier.layers])\n",
    "layer_index = 7\n",
    "input_img = classifier.input\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    \n",
    "    # build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = classifier.layers[layer_index].get_output_at(1)\n",
    "    \n",
    "    loss = K.mean(layer_output[:, :, :, i])\n",
    "    \n",
    "    # compute the gradient of the loss wrt the input picture\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "    \n",
    "    # we start from a gray image with some noise\n",
    "    input_img_data = (np.random.random((1, IMG_SIZE, IMG_SIZE, 3)) - 0.5) * 20 + 128\n",
    "#     input_img_data = np.copy(x_test[82]).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "    # run gradient ascent for 20 steps\n",
    "    for j in range(5):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * 0.1\n",
    "        input_img_data = 0.95 * input_img_data\n",
    "        input_img_data = cv2.GaussianBlur(input_img_data[0, :], (1, 1), 0)\n",
    "        input_img_data = input_img_data.reshape(1, 32, 32, 3)\n",
    "    \n",
    "    img = input_img_data[0]\n",
    "    img = deprocess_image(img)\n",
    "    fig.add_subplot(rows, columns, i)   \n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in classifier.layers])\n",
    "layer_index = 7\n",
    "input_img = classifier.input\n",
    "\n",
    "layer_output = classifier.layers[layer_index].get_output_at(1)\n",
    "mean_activation_i = K.mean(layer_output[:, :, :, 36])\n",
    "iterate = K.function([input_img], [mean_activation_i])\n",
    "\n",
    "(cars_x_train, _, _, _) = select_car_images()\n",
    "mean_values = []\n",
    "for car in cars_x_train:\n",
    "    mean_activ_value = iterate([car.reshape(1, IMG_SIZE, IMG_SIZE, 3)])\n",
    "    mean_values.append(mean_activ_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = np.array(mean_values)\n",
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)\n",
    "\n",
    "# 12 is diagonal right\n",
    "boom = largest_indices(mean_values, 5)\n",
    "print(mean_values[boom])\n",
    "print(boom)\n",
    "plt.imshow(x_test[1193])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Breakdown + misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What this classifier classifies as cars: \n",
      " {'plane': 62, 'car': 879, 'bird': 16, 'cat': 19, 'deer': 12, 'dog': 6, 'frog': 19, 'horse': 10, 'ship': 159, 'truck': 299}\n",
      "Total population of test set: \n",
      " {'plane': 1000, 'car': 1000, 'bird': 1000, 'cat': 1000, 'deer': 1000, 'dog': 1000, 'frog': 1000, 'horse': 1000, 'ship': 1000, 'truck': 1000}\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "predictions[predictions < 0.5] = 0\n",
    "predictions[predictions >= 0.5] = 1\n",
    "\n",
    "category_of = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "table = { 'plane': 0,'car': 0, 'bird': 0, 'cat': 0, 'deer': 0, 'dog': 0, 'frog': 0, 'horse': 0, 'ship': 0, 'truck': 0}\n",
    "total_counts = { 'plane': 0,'car': 0, 'bird': 0, 'cat': 0, 'deer': 0, 'dog': 0, 'frog': 0, 'horse': 0, 'ship': 0, 'truck': 0}\n",
    "\n",
    "misclassified_as_cars = []\n",
    "cars_i = []\n",
    "cars_misclassified_as_not = []\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    c = category_of[y_test[i][0]]\n",
    "    total_counts[c] += 1\n",
    "    if predictions[i] == 1:\n",
    "        if c != 'car':\n",
    "            misclassified_as_cars.append(i)\n",
    "        else:\n",
    "            cars_i.append(i)\n",
    "        table[c] += 1\n",
    "    if predictions[i] != 1 and c == 'car':\n",
    "            cars_misclassified_as_not.append(i)\n",
    "        \n",
    "print(\"What this classifier classifies as cars: \\n\", table)\n",
    "print(\"Total population of test set: \\n\", total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4498.0\n",
      "4498\n",
      "4112\n",
      "(8612, 1)\n"
     ]
    }
   ],
   "source": [
    "train_predictions = classifier.predict(salient_not_cars_train_x)\n",
    "train_predictions[train_predictions < 0.5] = 0\n",
    "train_predictions[train_predictions >= 0.5] = 1\n",
    "print(np.sum(train_predictions))\n",
    "print(len(np.where(train_predictions == 1)[0]))\n",
    "print(len(np.where(salient_not_cars_train_y == 1)[0]))\n",
    "print(train_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epoch 1:  \n",
    "{'plane': 396, 'car': 886, 'bird': 169, 'cat': 250, 'deer': 138, 'dog': 186, 'frog': 176, 'horse': 176, 'ship': 580, 'truck': 807}    \n",
    "After epoch 2:  \n",
    "{'plane': 63, 'car': 673, 'bird': 36, 'cat': 29, 'deer': 11, 'dog': 12, 'frog': 13, 'horse': 16, 'ship': 146, 'truck': 349}   \n",
    "After epoch 3:   \n",
    "{'plane': 41, 'car': 594, 'bird': 12, 'cat': 6, 'deer': 5, 'dog': 4, 'frog': 2, 'horse': 4, 'ship': 82, 'truck': 293}   \n",
    "After epoch 5:  \n",
    "{'plane': 90, 'car': 828, 'bird': 43, 'cat': 26, 'deer': 15, 'dog': 21, 'frog': 18, 'horse': 30, 'ship': 165, 'truck': 491}    \n",
    "After epoch 10:  \n",
    "{'plane': 72, 'car': 807, 'bird': 20, 'cat': 18, 'deer': 15, 'dog': 9, 'frog': 13, 'horse': 12, 'ship': 111, 'truck': 363}  \n",
    "After epoch 15:  \n",
    " {'plane': 66, 'car': 821, 'bird': 21, 'cat': 32, 'deer': 16, 'dog': 12, 'frog': 24, 'horse': 14, 'ship': 90, 'truck': 331}  \n",
    "After epoch 21:  \n",
    "{'plane': 82, 'car': 862, 'bird': 24, 'cat': 37, 'deer': 17, 'dog': 12, 'frog': 29, 'horse': 11, 'ship': 162, 'truck': 472}  \n",
    "After epoch 26:  \n",
    "{'plane': 85, 'car': 900, 'bird': 34, 'cat': 45, 'deer': 22, 'dog': 13, 'frog': 29, 'horse': 36, 'ship': 164, 'truck': 468}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 1 epoch of dta augmentation of original + black car images + black not cars:  \n",
    "{'plane': 165, 'car': 789, 'bird': 83, 'cat': 182, 'deer': 113, 'dog': 89, 'frog': 135, 'horse': 161, 'ship': 270, 'truck': 628}   \n",
    "After 2 epochs:   \n",
    "{'plane': 138, 'car': 783, 'bird': 41, 'cat': 63, 'deer': 34, 'dog': 39, 'frog': 42, 'horse': 52, 'ship': 244, 'truck': 578}  \n",
    "After 3 epochs:  \n",
    "{'plane': 60, 'car': 560, 'bird': 13, 'cat': 16, 'deer': 10, 'dog': 6, 'frog': 5, 'horse': 12, 'ship': 78, 'truck': 241}  \n",
    "After 4 epochs:   \n",
    "{'plane': 48, 'car': 710, 'bird': 14, 'cat': 12, 'deer': 9, 'dog': 4, 'frog': 7, 'horse': 11, 'ship': 111, 'truck': 293}  \n",
    "After 5 epochs:  \n",
    "{'plane': 97, 'car': 840, 'bird': 13, 'cat': 20, 'deer': 18, 'dog': 9, 'frog': 22, 'horse': 28, 'ship': 191, 'truck': 461}  \n",
    "After 6 epochs:   \n",
    "{'plane': 42, 'car': 761, 'bird': 9, 'cat': 10, 'deer': 5, 'dog': 1, 'frog': 5, 'horse': 9, 'ship': 113, 'truck': 311}  \n",
    "After 8 epochs:  \n",
    "{'plane': 40, 'car': 784, 'bird': 9, 'cat': 10, 'deer': 4, 'dog': 2, 'frog': 9, 'horse': 3, 'ship': 129, 'truck': 315}  \n",
    "After 10 epochs:  \n",
    "{'plane': 32, 'car': 787, 'bird': 9, 'cat': 13, 'deer': 12, 'dog': 3, 'frog': 13, 'horse': 12, 'ship': 88, 'truck': 248}  \n",
    "After 12 epochs:  \n",
    "{'plane': 52, 'car': 887, 'bird': 17, 'cat': 14, 'deer': 11, 'dog': 7, 'frog': 18, 'horse': 11, 'ship': 159, 'truck': 394}  \n",
    "After 15 epochs:  \n",
    " {'plane': 51, 'car': 856, 'bird': 16, 'cat': 15, 'deer': 13, 'dog': 4, 'frog': 15, 'horse': 10, 'ship': 118, 'truck': 282}  \n",
    "After 17 epochs:   \n",
    "{'plane': 95, 'car': 887, 'bird': 28, 'cat': 22, 'deer': 13, 'dog': 12, 'frog': 28, 'horse': 24, 'ship': 167, 'truck': 349}  \n",
    "After 19 epochs:  \n",
    "{'plane': 62, 'car': 879, 'bird': 16, 'cat': 19, 'deer': 12, 'dog': 6, 'frog': 19, 'horse': 10, 'ship': 159, 'truck': 299}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save(\"saliency works! 879_epochs_19_car_conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(x_test[953].reshape(1, IMG_SIZE, IMG_SIZE, 3))\n",
    "print(result)\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "# 90\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = x_test[cars_misclassified_as_not[i]]\n",
    "    print(cars_misclassified_as_not[i])\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
